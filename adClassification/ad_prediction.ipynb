{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ad_prediction.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mwpbNzIWkTZo"},"source":["!git clone https://github.com/SKTBrain/KoBERT.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2lCl5rs2LZY"},"source":["cd KoBERT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJbSjWef4sza"},"source":["!pip install tqdm # progressbar 사용\n","\n","!pip install -r requirements.txt\n","!pip install .\n","!pip install torch\n","\n","# transformers 의 경우 최신 버전으로 설치 시 에러 발생\n","!pip install transformers #==3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JLaSXfDqjC3"},"source":["import os\n","import pandas as pd\n","import numpy as np\n","import csv \n","import sys\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","import gluonnlp as nlp\n","from torch.utils.data import Dataset, DataLoader\n","\n","# from kobert_transformers import get_kobert_model, get_distilkobert_model\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","from tqdm import tqdm, tqdm_notebook\n","\n","from tqdm import trange"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 환경 세팅"],"metadata":{"id":"BWmtRTyQimp8"}},{"cell_type":"code","source":["# pytorch 에러 때문에 버전 확인\n","print(sys.version)\n","print(\"Torch version:{}\".format(torch.__version__))\n","print(\"cuda version: {}\".format(torch.version.cuda))\n","print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"],"metadata":{"id":"KzcIpHsGh_KB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GPU 사용을 위해\n","device = torch.device(\"cuda:0\")"],"metadata":{"id":"z_R-HOzch9Wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MuHUNziVh9gb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습된 모델 불러오기"],"metadata":{"id":"LxJu7GKzipsx"}},{"cell_type":"code","source":["model_saved_path = \"/content/drive/MyDrive/forColab/learned_model/model3.pt\""],"metadata":{"id":"V23Ex7wgGngY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting parameters\n","max_len = 128 \n","batch_size = 16\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate = 5e-5"],"metadata":{"id":"u31hTQvbtL_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTDataset(Dataset):\n","    # sentences 의 index와 label index 매개변수 제거\n","    def __init__(self, dataset, bert_tokenizer, max_len, pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n","\n","      # sentences 리스트와 label 리스트를 만드는 코드 변경\n","        self.sentences = [transform([i]) for i in dataset['contents']]\n","        self.labels = list(dataset['label'])\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"W74_aZdri3FW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768, # Dimensionality of the encoder layers and the pooler layer\n","                 num_classes = 3, # 분류할 class label의 개수                \n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"86Vj1xpyiic7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#광고 여부를 확인하는, 이미 학습된 모델 로딩\n","model_checkAd = torch.load(model_saved_path)"],"metadata":{"id":"O24S6yiZFKXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3lCpeuwY5gs"},"source":["# 이미 pre train 된 bert 모델과 vocab을 불러옴\n","bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rMU48hMY5jk"},"source":["# 위에서 불러온 vocab을 이용하여 토크나이저 선언\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 광고 유무 확인 코드"],"metadata":{"id":"O61O-KPHjuBK"}},{"cell_type":"code","metadata":{"id":"MKhXQacpkBPD"},"source":["class Advertisement:\n","\n","  def check_ad(self, lst):\n","    _data = self.format_for_test(lst)\n","    _dataset = BERTDataset(_data, tok, max_len, True, False)\n","    _dataloader = torch.utils.data.DataLoader(_dataset, batch_size=batch_size, num_workers=5, shuffle=False)\n","    pred = np.mean(self.predict(_dataloader))\n","    if pred < 1: return True\n","    else: return False\n","\n","  def format_for_test(self, sentence):\n","    data_format = pd.DataFrame()\n","    data_format['contents'] = sentence\n","    data_format['label'] = pd.Series([0] * len(sentence))\n","    return data_format\n","\n","  def predict(self, _dataloader):\n","    lst_results = []\n","    model_checkAd.eval()\n","    # for batch_id, (token_ids, valid_length, segment_ids) in enumerate(_dataloader):\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model_checkAd(token_ids, valid_length, segment_ids)\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","            lst_results.append(np.argmax(logits))\n","    return lst_results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8HvAw1Uvp9S"},"source":["# 광고 유무 판단"]},{"cell_type":"code","source":["data_name = 'gangnam_pizza'\n","\n","dir_path = '/content/drive/MyDrive/forColab/final/' + data_name + '/'\n","\n","file_save_path = dir_path + 'summary/'\n","os.mkdir(file_save_path)\n","save_file_path = file_save_path + data_name + '.csv'"],"metadata":{"id":"JKmGiTtezwPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HBc5R4GDq09X"},"source":["file_list = os.listdir(dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ad = Advertisement()"],"metadata":{"id":"AWFs8iORlPKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gylx8xdpq1Ao"},"source":["df_data = pd.DataFrame(columns=['title', 'restaurant', 'ad'])\n","\n","for i in trange(len(file_list)):\n","  f = open(dir_path + 'blog_data_'+ str(i)+'.txt', 'r')\n","  file_text = f.readlines()\n","  f.close()\n","\n","  # title\n","  title = file_text[2][1:-1]\n","  # restaurant\n","  restaurant = file_text[4][1:-1]\n","  # text\n","  text = [file_text[i][1:-1]for i in range(6, len(file_text)-2)]\n","  #prediction\n","  pred = ad.check_ad(text)\n","\n","  df_data = df_data.append({'title': title, 'restaurant': restaurant, 'ad' : pred}, ignore_index=True)\n","df_data.to_csv(save_file_path, encoding='utf-8-sig', header=False, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LyPAOh3j5KSr"},"execution_count":null,"outputs":[]}]}